{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost calculator for serving data from a Databricks SQl Warehouse (serverless) to the insight automation app.\n",
    "\n",
    "It is expected that when a report is created several concurrent api requests will be made to the Warehouse, testing has shown that even the smallest available warehouse can handle 1000 concurrent requests without issue and serve the query results rapidly.\n",
    "\n",
    "The primary driver of costs here is the compute uptime, which is a function of the time distribution of requests, the computes hourly DBU rate, and it's autotermination settings.\n",
    "\n",
    "If the compute is terminated an incoming request will cause it to start up, once started it will serve any requests made, if no requests are made for the duration of the autotermination wait period then the cluster will terminate. The autotermination period starts from the completion of the last piece work assigned to the compute.\n",
    "\n",
    "As as example suppose the autotermination is set to 10 minutes, then we can have the following two scenarios:\n",
    "\n",
    "    17:00:00 Request received.\n",
    "    17:00:01 Compute started\n",
    "    17:00:05 Request completed.\n",
    "    17:10:05 Compute terminated.\n",
    "\n",
    "    17:12:00 Request received.\n",
    "    17:12:01 Compute started\n",
    "    17:12:05 Request completed.\n",
    "    17:22:05 Compute terminated.\n",
    "\n",
    "Total Uptime 20 minutes and 8 seconds to serve two requests.\n",
    "\n",
    "    17:00:00 Request received.\n",
    "    \n",
    "    17:00:01 Compute started\n",
    "    17:00:05 Request completed.\n",
    "\n",
    "    17:07:00 Request received.\n",
    "    17:07:04 Request completed.\n",
    "    17:17:04 Compute terminated.\n",
    "\n",
    "Total Uptime 17 minutes and 3 seconds to serve two requests.\n",
    "\n",
    "This is relevant because clustered requests are more cost efficient, and so when calculating the cost of serving data to the reports generated we need to consider clustered requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost variables\n",
    "# These are variables which directly affect the compute cost of providing data to the insight automation app.\n",
    "# Given that even the smallest serverless warehouse can happily handle 1000 + concurrent requests and server them all with 60 seconds,\n",
    "# the primary cost driver is the uptime of the warehouse.\n",
    "\n",
    "\n",
    "\n",
    "cluster_auto_termination_minutes = 10\n",
    "cluster_hourly_dbu_cost = 6\n",
    "dbu_cost = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = pd.read_csv('data/report_intervals.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df[\"CreatedOn\"] = pd.to_datetime(df[\"CreatedOn\"])\n",
    "df[\"ProjectedComputeShutdown\"] = df[\"CreatedOn\"] + pd.to_timedelta(cluster_auto_termination_minutes, unit='m')\n",
    "df = df.sort_values(\"CreatedOn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = []\n",
    "current_interval = None\n",
    "for _, row in df.iterrows():\n",
    "    if current_interval is None:\n",
    "        current_interval = {\"start\": row[\"CreatedOn\"], \"end\": row[\"ProjectedComputeShutdown\"]}\n",
    "    else:\n",
    "        if row[\"CreatedOn\"] <= current_interval[\"end\"]:\n",
    "            current_interval[\"end\"] = max(current_interval[\"end\"], row[\"ProjectedComputeShutdown\"])\n",
    "        else:\n",
    "            intervals.append(current_interval)\n",
    "            current_interval = {\"start\": row[\"CreatedOn\"], \"end\": row[\"ProjectedComputeShutdown\"]}\n",
    "\n",
    "if current_interval is not None:\n",
    "    intervals.append(current_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics & cost for the 2415 reports created in 2024 had we used a serverless warehouse, \n",
      "    with a cluster auto-termination of 10 minutes, consuming 6 an hour with a DBU cost of £1.25.\n",
      "#################### stats and cost ####################\n",
      "      cluster_uptime_hours  cluster_uptime_minutes  dbus_consumed  \\\n",
      "sum             318.577344            19114.640661    1911.464066   \n",
      "mean              0.197018               11.821052       1.182105   \n",
      "max               0.722052               43.323096       4.332310   \n",
      "min               0.166667               10.000000       1.000000   \n",
      "\n",
      "      sterling_cost  \n",
      "sum     2389.330083  \n",
      "mean       1.477631  \n",
      "max        5.415387  \n",
      "min        1.250000  \n"
     ]
    }
   ],
   "source": [
    "count_of_reports = len(df)\n",
    "intervals_df = pd.DataFrame(intervals)\n",
    "intervals_df[\"cluster_uptime_hours\"] = (intervals_df[\"end\"] - intervals_df[\"start\"]).dt.total_seconds() / 3600\n",
    "intervals_df[\"cluster_uptime_minutes\"] = (intervals_df[\"end\"] - intervals_df[\"start\"]).dt.total_seconds() / 60\n",
    "\n",
    "\n",
    "agg_df = intervals_df.agg({\"cluster_uptime_hours\": [\"sum\", \"mean\", \"max\", \"min\"],\"cluster_uptime_minutes\": [\"sum\", \"mean\", \"max\", \"min\"]})\n",
    "agg_df[\"dbus_consumed\"] = agg_df[\"cluster_uptime_hours\"] * cluster_hourly_dbu_cost\n",
    "agg_df[\"sterling_cost\"] = agg_df[\"dbus_consumed\"] * dbu_cost\n",
    "\n",
    "print(\n",
    "    f\"\"\"Statistics & cost for the {count_of_reports} reports created in 2024 had we used a serverless warehouse, \n",
    "    with a cluster auto-termination of {cluster_auto_termination_minutes} minutes, consuming {cluster_hourly_dbu_cost} an hour with a DBU cost of £{dbu_cost}.\"\"\"\n",
    "    )\n",
    "print(\"#\"*20, \"stats and cost\", \"#\"*20)\n",
    "print(agg_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
